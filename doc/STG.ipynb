{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f465912d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:49:32.375537Z",
     "start_time": "2022-01-27T09:49:29.161732Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10\n",
    "\n",
    "from tensorflow.keras.layers import Layer, Dense, Input, Dropout, BatchNormalization, LeakyReLU, Lambda\n",
    "from tensorflow.keras.layers import Subtract, Add, MaxPooling2D, LayerNormalization\n",
    "from tensorflow.keras.initializers import RandomNormal, RandomUniform, GlorotNormal, Constant, GlorotUniform\n",
    "from tensorflow.keras.constraints import Constraint, NonNeg\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l1_l2, l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "from tensorflow.keras.layers import Reshape, Conv2D, Flatten, Conv1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.io import loadmat\n",
    "import tikzplotlib\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from itertools import combinations\n",
    "\n",
    "import math\n",
    "import os                          \n",
    "import random as rn\n",
    "import gc                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ad6ba",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194133c",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beacd282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "        self.datasets = None\n",
    "\n",
    "    def load_data(self, normalize=True, **kwargs):\n",
    "        if self.name == 'mnist':\n",
    "            (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "            x_train = (np.reshape(x_train, newshape=(len(x_train), -1)) / 255).astype(np.float32)\n",
    "            y_train = y_train.astype(np.float32)\n",
    "            x_test = (np.reshape(x_test, newshape=(len(x_test), -1)) / 255).astype(np.float32)\n",
    "            y_test = y_test.astype(np.float32)\n",
    "        else:\n",
    "            raise ValueError('Please enter a valid realtion mode...')\n",
    "\n",
    "        self.x_train, self.y_train, self.x_test, self.y_test = x_train, y_train, x_test, y_test\n",
    "        self.input_shape = x_train.shape[1:]\n",
    "        return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547addc1",
   "metadata": {},
   "source": [
    "# FeatureSelectionLayer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f92b4879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:49:57.695430Z",
     "start_time": "2022-01-27T09:49:57.689974Z"
    }
   },
   "outputs": [],
   "source": [
    "def mu_regularizer(x):\n",
    "    sigma = 0.5\n",
    "    inner = (x+0.5)/sigma\n",
    "    reg = tf.reduce_mean(0.5 * (1 + tf.math.erf(inner/math.sqrt(2))))\n",
    "    return reg\n",
    "\n",
    "\n",
    "class FeatureSelector(Layer):       \n",
    "    def __init__(self, input_dim, lam, sigma, **kwargs):\n",
    "        #param kwargs: The name of this layer.\n",
    "\n",
    "        super(FeatureSelector, self).__init__(**kwargs)\n",
    "        self.sigma = sigma\n",
    "        self.lam = lam\n",
    "        self.num_fea = input_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(self.num_fea, ),\n",
    "                                  initializer=RandomNormal(stddev=1e-4),\n",
    "                                  regularizer=mu_regularizer,\n",
    "                                  trainable=True)\n",
    "        \n",
    "    def call(self, prev_x):\n",
    "        z = self.mu + self.sigma * np.random.randn(self.num_fea)\n",
    "        stochastic_gate = tf.clip_by_value(z+0.5, 0.0, 1.0)            # set mu=0.5 at very first beginning\n",
    "        new_x = prev_x * stochastic_gate\n",
    "        \n",
    "        return new_x              \n",
    "    \n",
    "    #def get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814929c2",
   "metadata": {},
   "source": [
    "# HiddenNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6dc5561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:49:38.179363Z",
     "start_time": "2022-01-27T09:49:38.166962Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_HiddenModel(input_dim, output_dim, hidden_dims, task):\n",
    "\n",
    "    if hidden_dims is None:\n",
    "        hidden_dims = []\n",
    "    elif type(hidden_dims) is int:\n",
    "        hidden_dims = [hidden_dims]\n",
    "    dims = [input_dim]\n",
    "    dims.extend(hidden_dims)\n",
    "    dims.append(output_dim)\n",
    "    model = keras.Sequential(name=\"MLP_Learning\")\n",
    "\n",
    "    nr_hiddens = len(hidden_dims)\n",
    "    for i in range(nr_hiddens):\n",
    "        model.add(Dense(dims[i+1], activation=\"relu\"))      \n",
    "    \n",
    "    if task in ['regression']:\n",
    "        model.add(Dense(output_dim, activation=\"linear\", name='regression'))\n",
    "    elif task in ['classification']:\n",
    "        model.add(Dense(output_dim, activation=\"softmax\", name='classification'))\n",
    "    else:\n",
    "        raise ValueError ('Please enter a valid laearning task!')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d07945f",
   "metadata": {},
   "source": [
    "# Followings are for wrapping out the whole model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c25ad0",
   "metadata": {},
   "source": [
    "# ============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd00115",
   "metadata": {},
   "source": [
    "# STGï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3112f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:50:26.210908Z",
     "start_time": "2022-01-27T09:50:26.190576Z"
    }
   },
   "outputs": [],
   "source": [
    "class STG():\n",
    "\n",
    "    def __init__(self, task=\"classification\", input_dim=None, output_dim=None, hidden_dims=[60,20],\n",
    "                 learning_rate=0.1, lam=0.5, sigma=0.5, **kwargs):  \n",
    "\n",
    "        self.task = task\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.optimizer = Adam(learning_rate=self.learning_rate, decay=1e-9)\n",
    "\n",
    "        # ---------- define feature selection models ----------\n",
    "        input_layer = Input(shape=self.input_dim, name=\"InputLayer\")    \n",
    "        \n",
    "        selection_network = FeatureSelector(input_dim=self.input_dim, lam=self.lam, sigma=self.sigma, name=\"FS\", **kwargs )  \n",
    "        hiddenModel = get_HiddenModel(input_dim=self.input_dim, output_dim=self.output_dim, hidden_dims=self.hidden_dims, task=self.task)\n",
    "\n",
    "        x = selection_network(input_layer)           \n",
    "        output_layer = hiddenModel(x)                 \n",
    "\n",
    "        self.fs_wrapper = Model(inputs=input_layer, outputs=output_layer)    \n",
    "        self.selection_net = Model(inputs=input_layer, outputs=x)           \n",
    "        self.learning_net =hiddenModel                                     \n",
    "        \n",
    "\n",
    "        if task in ['classification']:\n",
    "            loss = 'sparse_categorical_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "        elif task in ['regression', 'unsupervised']:\n",
    "            loss = 'mse'\n",
    "            metrics = None\n",
    "        else:\n",
    "            raise ValueError('Please enter valid losses and metrics...')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.fs_wrapper.compile(optimizer=self.optimizer, loss=loss, metrics=metrics)    \n",
    "        self.selection_net.compile('sgd', 'mse', metrics)                \n",
    "        self.learning_net.compile('sgd', 'mse', metrics)        \n",
    "\n",
    "    def fit(self, x=None, y=None, **kwargs):\n",
    "        self.hist = self.fs_wrapper.fit(x=x, y=y, **kwargs)       \n",
    "        return self.hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1b994",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d723bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(name='mnist')\n",
    "data = dataset.load_data()\n",
    "model = STG(task=\"classification\", \n",
    "            input_dim=data[0].shape[1], \n",
    "            output_dim=10, \n",
    "            hidden_dims=[128,64,16],\n",
    "            learning_rate=1e-3, \n",
    "            lam=0.5, \n",
    "            sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244e4dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:50:27.225960Z",
     "start_time": "2022-01-27T09:50:27.109704Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 1.7251 - accuracy: 0.7265\n",
      "Epoch 2/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 1.0470 - accuracy: 0.9211\n",
      "Epoch 3/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.9168 - accuracy: 0.9412\n",
      "Epoch 4/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.8113 - accuracy: 0.9507\n",
      "Epoch 5/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.7174 - accuracy: 0.9582\n",
      "Epoch 6/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.9633\n",
      "Epoch 7/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.5668 - accuracy: 0.9668\n",
      "Epoch 8/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.9696\n",
      "Epoch 9/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.9718\n",
      "Epoch 10/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.9743\n",
      "Epoch 11/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.9758\n",
      "Epoch 12/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.3708 - accuracy: 0.9777\n",
      "Epoch 13/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.9794\n",
      "Epoch 14/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.9804\n",
      "Epoch 15/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3142 - accuracy: 0.9817\n",
      "Epoch 16/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9828\n",
      "Epoch 17/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2865 - accuracy: 0.9840\n",
      "Epoch 18/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9850\n",
      "Epoch 19/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2663 - accuracy: 0.9858\n",
      "Epoch 20/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.9862\n",
      "Epoch 21/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2483 - accuracy: 0.9873\n",
      "Epoch 22/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9875\n",
      "Epoch 23/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9881\n",
      "Epoch 24/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9894\n",
      "Epoch 25/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2215 - accuracy: 0.9899\n",
      "Epoch 26/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9900\n",
      "Epoch 27/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9913\n",
      "Epoch 28/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.2054 - accuracy: 0.9917\n",
      "Epoch 29/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9922\n",
      "Epoch 30/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1966 - accuracy: 0.9927\n",
      "Epoch 31/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9930\n",
      "Epoch 32/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9933\n",
      "Epoch 33/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.9931\n",
      "Epoch 34/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9938\n",
      "Epoch 35/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1799 - accuracy: 0.9940\n",
      "Epoch 36/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9948\n",
      "Epoch 37/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1729 - accuracy: 0.9953\n",
      "Epoch 38/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.9952\n",
      "Epoch 39/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.9962\n",
      "Epoch 40/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9959\n",
      "Epoch 41/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9961\n",
      "Epoch 42/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1622 - accuracy: 0.9961\n",
      "Epoch 43/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9973\n",
      "Epoch 44/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9968\n",
      "Epoch 45/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9972\n",
      "Epoch 46/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9974\n",
      "Epoch 47/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9970\n",
      "Epoch 48/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9978\n",
      "Epoch 49/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1496 - accuracy: 0.9973\n",
      "Epoch 50/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9976\n",
      "Epoch 51/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9977\n",
      "Epoch 52/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1447 - accuracy: 0.9984\n",
      "Epoch 53/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9982\n",
      "Epoch 54/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.9988\n",
      "Epoch 55/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.9988\n",
      "Epoch 56/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9986\n",
      "Epoch 57/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9987\n",
      "Epoch 58/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.9988\n",
      "Epoch 59/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1375 - accuracy: 0.9986\n",
      "Epoch 60/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9990\n",
      "Epoch 61/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1358 - accuracy: 0.9987\n",
      "Epoch 62/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.9992\n",
      "Epoch 63/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1328 - accuracy: 0.9993\n",
      "Epoch 64/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9991\n",
      "Epoch 65/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9992\n",
      "Epoch 66/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9996\n",
      "Epoch 67/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9997\n",
      "Epoch 68/70\n",
      "118/118 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9992\n",
      "Epoch 69/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1289 - accuracy: 0.9990\n",
      "Epoch 70/70\n",
      "118/118 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x211b4a8b040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=data[0],\n",
    "          y=data[1],\n",
    "          batch_size=512, \n",
    "          epochs=70,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d56e1",
   "metadata": {},
   "source": [
    "# Mask visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7069ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:51:05.598790Z",
     "start_time": "2022-01-27T09:51:05.593361Z"
    }
   },
   "outputs": [],
   "source": [
    "mu = model.selection_net.layers[-1].mu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99e89e92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:51:05.967165Z",
     "start_time": "2022-01-27T09:51:05.952284Z"
    }
   },
   "outputs": [],
   "source": [
    "z = mu + 0.5 * np.random.randn(784, )\n",
    "mask = tf.clip_by_value(z+0.5, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14050fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T09:51:06.564668Z",
     "start_time": "2022-01-27T09:51:06.428796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x211b5f3b640>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPbUlEQVR4nO3df5BV9XnH8c+z/FjGVSkEIfwyqMGJVBGTFTSYjo1p+GE6aCe28kfGtIxYJ0zDJKO1ZlKdznRqTaNNph0m2DCSNpVJokTb2iAlmWImKXEx6wJiA6UEl90CBhMQx4XdffrHHjIr7P3e5Z5777ns837N7Nx7z3PPOY93/HDuvd97ztfcXQBGvqaiGwBQH4QdCIKwA0EQdiAIwg4EMbqeOxtrzT5OLfXcJRDKOzqhk95jQ9Vyhd3MFkv6iqRRkv7B3R9JPX+cWrTAbsmzSwAJ23xLyVrFb+PNbJSkv5e0RNIcScvNbE6l2wNQW3k+s8+XtNfd97n7SUkbJC2rTlsAqi1P2KdLen3Q485s2buY2UozazOztlPqybE7AHnkCftQXwKc9dtbd1/r7q3u3jpGzTl2ByCPPGHvlDRz0OMZkrrytQOgVvKE/SVJs83sMjMbK+lOSc9Vpy0A1Vbx0Ju795rZKkmbNDD0ts7dd1WtMwBVlWuc3d2fl/R8lXoBUEP8XBYIgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIOo6ZTMK0DQqXe/vq08fDebQn3w4WZ/y1R/VqZP64cgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzj7CbercnqwvmjYvWW+a+4Fkvb/jtXNt6dc2dbUn6+V6y2MkjqOXkyvsZrZf0nFJfZJ63b21Gk0BqL5qHNl/293fqMJ2ANQQn9mBIPKG3SW9YGbbzWzlUE8ws5Vm1mZmbafUk3N3ACqV9238QnfvMrPJkjab2WvuvnXwE9x9raS1knSxTfSc+wNQoVxHdnfvym4PS9ooaX41mgJQfRWH3cxazOyi0/clfVzSzmo1BqC68ryNnyJpo5md3s4/u/v3qtLVCDNqwoRkve/NN5P1POPR5caqT33sQ8n6mP9Ij9OX83+rS583fvOK65PrNuulXPvGu1UcdnffJ+naKvYCoIYYegOCIOxAEIQdCIKwA0EQdiAIc6/fj9outom+wG6p2/7OFz23lhmC+rf0ENSJ711estayeF9FPZ125N4bk/VL1vw41/ZTuj+Xvtzz1MeKO0315KL0CZ5jN7XVqZN32+ZbdMyP2lA1juxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EASXks6MnjkjWe99vbNm+y43jl7O+HtLT7vcm2vLki9On36rNZVv+/r29HTRb/X9JFnf/Vjl+x49fVqy3nuwK1kvahw9D47sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+yZWo6j19q+Ry8uWbv0jvS6H+l4J1m/seXbyfqjuia9g4QNm29K1q+4L32u/J6/W5Csz161rWTt7avT4+wXNI9N1nv37U/WGxFHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2Oli081iyvunq0uPkktR38weT9d+48Ffn3NNpG38+N1lfcnVHxdsu5/5PPJusP33f5GQ9NY5eTrnz0fNeB+DNT6evtz/hydpdb7+Uskd2M1tnZofNbOegZRPNbLOZ7clu0xOQAyjccN7GPylp8RnLHpC0xd1nS9qSPQbQwMqG3d23Sjp6xuJlktZn99dLuq26bQGotkq/oJvi7t2SlN2W/HBlZivNrM3M2k6pp8LdAcir5t/Gu/tad29199Yxaq717gCUUGnYD5nZVEnKbg9XryUAtVBp2J+TdFd2/y5J6TEUAIUrOz+7mT0l6WZJkyQdkvSQpO9K+pakSyUdkHSHu5/5Jd5Zos7P3nTtVcl6/yu769TJ2X72RHpu+CvvTl/T/sCfp+dQv/QvSs+hvqmrPbnuomnzkvVyUtu/4f4/Tq47/p/+K9e+i5Kan73sj2rcfXmJUrzUAucxfi4LBEHYgSAIOxAEYQeCIOxAEJziWgflhtZ6b/lQsj56y/aK973/L9OnWl55d/pUy3d+d36ynhpay+vAt9OXqZ7y5LhkfVHiatHjlW9o7Z1PpF+Xcf+anm66CBzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCIMOPs9v3pybp/9GDF28475ppnHL2cWV/Id8niE5NHJevNN16brNuPXylZW3EgPWXzjK+m//dsejF9+u2oSe8pWet74xfJdcuxvvSp4Y2IIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBBFmnD3POHo5RZ+77Imx7tQ493C8+Zvp8eRxv0yfU96SqHXe8FZy3Sb9NFkvd65+3t8YpDT/e3qMvxFxZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIMpO2VxNI3XK5r1/e0Oy/v7V+a5R3rMkPa1yLcd8b3/1SLK+cc4lyXrPraV7P3lR+lz5izYUN21y133pqainfal218vPIzVlc9kju5mtM7PDZrZz0LKHzeygmbVnf0ur2TCA6hvO2/gnJS0eYvnj7j4v+3u+um0BqLayYXf3rZKO1qEXADWU5wu6VWbWkb3Nn1DqSWa20szazKztlHpy7A5AHpWGfY2kKyTNk9Qt6culnujua9291d1bx6i5wt0ByKuisLv7IXfvc/d+SU9ISl9eFUDhKgq7mU0d9PB2STtLPRdAYyg7zm5mT0m6WdIkSYckPZQ9nifJJe2XdI+7d5fb2UgdZ89r31+nz8u+9WPpcfRnX76uZO3Ku8+/867r4cQnFyTrLd/ZVqdOqis1zl724hXuvnyIxV/P3RWAuuLnskAQhB0IgrADQRB2IAjCDgTBKa7D9L8b5pasXXZnR033PXrqe5P1ad89XrLW9Xvjk+u++sUZyfqLSx9L1m9Zf1+yPuuLtbucM86W6xRXACMDYQeCIOxAEIQdCIKwA0EQdiAIwg4EEWbK5rxqOZa+qas9WV80bV6yvvfY+0rWHtr6L8l1//A//yhZX3HpTcn6LKXH0UdfPqtkrXff/uS6tdR0wQXJev/bb9epk/rhyA4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQXA+ex18dMeJZP3717Qk603z5iTr/e2vnnNP1dL/kdKXsZakphd/WqdOIHE+OwARdiAMwg4EQdiBIAg7EARhB4Ig7EAQnM9eB+XG0Zfs+mWyfvjkzvT2u68sWRu/dG9y3dHTpyXrb18zPVlf97XHk/VVC/+gZK2382By3VFXzU7Wj181MVm/4Jnzc9rlWil7ZDezmWb2AzPbbWa7zOyz2fKJZrbZzPZktxNq3y6ASg3nbXyvpM+7+1WSbpD0GTObI+kBSVvcfbakLdljAA2qbNjdvdvdX87uH5e0W9J0Scskrc+etl7SbTXqEUAVnNMXdGY2S9J1krZJmuLu3dLAPwiSJpdYZ6WZtZlZ2yn15GwXQKWGHXYzu1DS05JWu/ux4a7n7mvdvdXdW8eouZIeAVTBsMJuZmM0EPRvuvsz2eJDZjY1q0+VdLg2LQKohrKnuJqZaeAz+VF3Xz1o+Zck/cLdHzGzByRNdPf7U9uKeoprOSc+uSBZb/lO5UNIGzt/kqzfPmN+xduuNRudHhn23t46dXL+SJ3iOpxx9oWSPiVph5m1Z8selPSIpG+Z2QpJByTdUYVeAdRI2bC7+w8lDfkvhSQO08B5gp/LAkEQdiAIwg4EQdiBIAg7EASXkg7ujXtuTNYnfS09JTMaC5eSBkDYgSgIOxAEYQeCIOxAEIQdCIKwA0FwKekR4Mi9pcfKfzU7/TuK938uPY7eNPcDyXp/x2vJeh6df/bhZP3U3PRU2Jctf6Vkrcj/rqJwZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhnHwEuWVN6rNzKnK9+fXtfsv7C4+nJeSd0JMu5zPirH9Vs2yNxHL0cjuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMRw5mefKekbkt4rqV/SWnf/ipk9LOluSUeypz7o7s+ntsV144Hayjs/e6+kz7v7y2Z2kaTtZrY5qz3u7n9TrUYB1M5w5mfvltSd3T9uZrslTa91YwCq65w+s5vZLEnXSdqWLVplZh1mts7MhvxdpZmtNLM2M2s7pZ583QKo2LDDbmYXSnpa0mp3PyZpjaQrJM3TwJH/y0Ot5+5r3b3V3VvHqDl/xwAqMqywm9kYDQT9m+7+jCS5+yF373P3fklPSJpfuzYB5FU27GZmkr4uabe7PzZo+dRBT7td0s7qtwegWobzbfxCSZ+StMPM2rNlD0pabmbzJLmk/ZLuqUF/KFjX/enLOU97tHanoaK6hvNt/A8lDTVulxxTB9BY+AUdEARhB4Ig7EAQhB0IgrADQRB2IAguJY0kxtFHDo7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxBE2UtJV3VnZkck/XzQokmS3qhbA+emUXtr1L4keqtUNXt7n7tfMlShrmE/a+dmbe7eWlgDCY3aW6P2JdFbperVG2/jgSAIOxBE0WFfW/D+Uxq1t0btS6K3StWlt0I/swOon6KP7ADqhLADQRQSdjNbbGb/bWZ7zeyBInooxcz2m9kOM2s3s7aCe1lnZofNbOegZRPNbLOZ7cluh5xjr6DeHjazg9lr125mSwvqbaaZ/cDMdpvZLjP7bLa80Ncu0VddXre6f2Y3s1GSfibpdyR1SnpJ0nJ3f7WujZRgZvsltbp74T/AMLPfkvSWpG+4+9XZskclHXX3R7J/KCe4+582SG8PS3qr6Gm8s9mKpg6eZlzSbZI+rQJfu0Rfv686vG5FHNnnS9rr7vvc/aSkDZKWFdBHw3P3rZKOnrF4maT12f31Gvifpe5K9NYQ3L3b3V/O7h+XdHqa8UJfu0RfdVFE2KdLen3Q40411nzvLukFM9tuZiuLbmYIU9y9Wxr4n0fS5IL7OVPZabzr6Yxpxhvmtatk+vO8igj7UFNJNdL430J3/6CkJZI+k71dxfAMaxrvehlimvGGUOn053kVEfZOSTMHPZ4hqauAPobk7l3Z7WFJG9V4U1EfOj2DbnZ7uOB+fq2RpvEeappxNcBrV+T050WE/SVJs83sMjMbK+lOSc8V0MdZzKwl++JEZtYi6eNqvKmon5N0V3b/LknPFtjLuzTKNN6lphlXwa9d4dOfu3vd/yQt1cA38v8j6QtF9FCir8slvZL97Sq6N0lPaeBt3SkNvCNaIek9krZI2pPdTmyg3v5R0g5JHRoI1tSCertJAx8NOyS1Z39Li37tEn3V5XXj57JAEPyCDgiCsANBEHYgCMIOBEHYgSAIOxAEYQeC+H9yq9SEEahwmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask.numpy().reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3101371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01137788,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.36455684, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.13487679,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.04696766, 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.2093983 , 0.        , 0.        , 0.37164381,\n",
       "       0.2238417 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.23200021, 0.        , 0.67900229, 0.        , 0.        ,\n",
       "       0.34442739, 0.        , 0.        , 0.        , 0.38270182,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.21735295,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.08299142,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09485592, 0.        , 0.        , 0.64555511, 0.        ,\n",
       "       0.        , 0.80008092, 0.78101661, 0.        , 0.        ,\n",
       "       0.07778209, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.61871655, 0.        ,\n",
       "       0.81116171, 0.89458526, 0.        , 0.        , 0.48618384,\n",
       "       0.        , 0.52175066, 0.        , 0.21780585, 0.09797769,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.82739086, 0.        ,\n",
       "       0.19238575, 0.67023889, 0.        , 0.65425826, 0.92147318,\n",
       "       0.        , 0.        , 0.84485985, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.31183733,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.14055524, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5532271 , 0.        , 0.43267339, 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.29484259,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.2033589 , 0.        , 0.        , 0.45748591, 0.        ,\n",
       "       0.24096426, 0.        , 0.0017546 , 1.        , 0.61738301,\n",
       "       0.2306824 , 0.        , 0.        , 0.        , 0.23640556,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.70401671, 0.        ,\n",
       "       0.        , 0.23576842, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32400772, 0.17068669,\n",
       "       0.        , 0.75495853, 0.18454585, 0.        , 0.05517513,\n",
       "       0.        , 0.        , 0.22540982, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.16893115, 0.        ,\n",
       "       0.        , 0.49916629, 0.25903154, 0.        , 0.        ,\n",
       "       0.        , 0.45968151, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00287995, 0.50589635, 0.        , 0.        ,\n",
       "       0.22431807, 0.        , 0.        , 0.        , 0.84155914,\n",
       "       0.        , 0.23289197, 0.28048228, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.39254934, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.47891833, 0.77774651, 0.55188666,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.26201184,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.60565185, 0.        , 0.        ,\n",
       "       0.        , 0.07373808, 0.75943461, 0.07547741, 0.53984052,\n",
       "       0.95530788, 0.45067969, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.68777936, 0.90126656, 0.56569763, 0.        , 0.        ,\n",
       "       0.1009124 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.03029398, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.81713832, 0.        , 0.14242955, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.18518295, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.82904338,\n",
       "       0.79672413, 0.6653573 , 0.        , 0.07551345, 0.22212474,\n",
       "       0.94585911, 0.0792419 , 0.        , 0.11840095, 0.25510454,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26208179, 0.        , 0.        ,\n",
       "       0.9812274 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.0137219 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33661569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.34625992, 0.49874479, 0.        , 0.13442383, 0.        ,\n",
       "       0.        , 0.        , 0.41394495, 0.60494678, 0.        ,\n",
       "       0.13632077, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33643224,\n",
       "       0.79984936, 0.30674982, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.39480539, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4808190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
